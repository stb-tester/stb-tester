//#version 120
precision mediump float;

/*
 * The point in the output video that we need to provide a colour for.  Ranges
 * between (0.0, 0.0) to (1.0, 1.0) corresponding to (0, 0), (1280, 720):
 */
varying vec2 v_texcoord;

/*
 * The input video frame
 */
uniform sampler2D tex;

struct Camera {
    /*
     * Variables describing the camera matrix:
     *
     * [ fx   0   cx ]
     * [ 0    fy  cy ]
     * [ 0    0    1 ]
     */
    vec2 f;
    vec2 c;

    /*
     * The distortion coefficients further describing the camera:
     *
     * [ k1, k2, p1, p2, k3 ]
     */
    vec3 k;
    vec2 p;

    /*
     * The inverse homography matrix describing the location of the TV in the
     * image.
     */
    mat3 inv_homography;

    /*
     * The mapping from input colour to output colour
     */
   // float color_map_r[256];
   // float color_map_g[256];
   // float color_map_b[256];
};

{% for c in cameras %}

const Camera {{ c.name }}_camera = Camera(
    /* f = */ vec2({{ c.geometric_params.fx }}, {{ c.geometric_params.fy }}),
    /* c = */ vec2({{ c.geometric_params.cx }}, {{ c.geometric_params.cy }}),
    /* k = */ vec3({{ c.geometric_params.k1 }}, {{ c.geometric_params.k2 }}, {{ c.geometric_params.k3 }}),
    /* p = */ vec2({{ c.geometric_params.p1 }}, {{ c.geometric_params.p2 }}),

    /* inv_homography = */
    mat3(
        {{ c.geometric_params.ihm11 }}, {{ c.geometric_params.ihm12 }}, {{ c.geometric_params.ihm13 }},
        {{ c.geometric_params.ihm21 }}, {{ c.geometric_params.ihm22 }}, {{ c.geometric_params.ihm23 }},
        {{ c.geometric_params.ihm31 }}, {{ c.geometric_params.ihm32 }}, {{ c.geometric_params.ihm33 }}));

{% endfor %}

/*
 * The distortion coefficients further describing the camera:
 *
 * [ k1, k2, p1, p2, k3 ]
 */
vec3 top_k = vec3(0.0, 0.0, 0.0);
vec2 top_p = vec2(0.0, 0.0);
vec3 bottom_k = vec3(0.0, 0.0, 0.0);
vec2 bottom_p = vec2(0.0, 0.0);

/*
 * The inverse homography matrix describing the location of the TV in the image.
 */
mat3 top_inv_homography_matrix = mat3(
    1.5, 0.0, 0.0,
    0.0, 1.5, 0.0,
    0.25, 0.25, 1.0);

mat3 bottom_inv_homography_matrix = mat3(
    1.5, 0.0, 0.0,
    0.0, 1.5, 0.0,
    0.25, 0.25, 1.0);

vec2 world_to_camera(vec3 v, vec2 f, vec2 c)
{
    mat3 camera_matrix = mat3(
        f.x, 0.0, 0.0,
        0.0, f.y, 0.0,
        c.x, c.y, 1.0);

    vec3 o = camera_matrix * v;
    return vec2(o[0], o[1]);
}

vec2 perspective_transform(vec2 src, mat3 m)
{
    vec3 v =  m * vec3(src, 1.0);

    float w = v[2];
    if( w != 0. ) {
        v /= w;
        return vec2(v[0], v[1]);
    } else
        return vec2(0.0, 0.0);
}

vec2 apply_camera_distortion(vec2 src, vec3 k, vec2 p)
{
    float r2 = dot(src, src);
    float r4 = r2 * r2;
    float r6 = r2 * r2 * r2;

    float radial_factor = 1.0 + dot(k, vec3(r2, r4, r6));

    return vec2(
        src.x * radial_factor
        + 2.0 * p[0] * src.x * src.y
        + p[1] * (r2 + 2.0 * src.x * src.x),
        src.y * radial_factor
        + 2.0 * p[1] * src.x * src.y
        + p[0] * (r2 + 2.0 * src.y * src.y));
}

/*
 * Transform a pixel location in the output 1280x720 image into a pixel location
 * in the input 1920x1080 image.
 */
vec2 transform_coordinates(vec2 in_coord, Camera camera)
{
    in_coord = perspective_transform(in_coord, camera.inv_homography);

    vec2 distorted = apply_camera_distortion(in_coord, camera.k, camera.p);
    return world_to_camera(vec3(distorted, 1.0), camera.f, camera.c);
}

void main()
{
    float top_camera_color_map_r[256];
    float top_camera_color_map_g[256];
    float top_camera_color_map_b[256];
    float bottom_camera_color_map_r[256];
    float bottom_camera_color_map_g[256];
    float bottom_camera_color_map_b[256];

{% for c in cameras %}
 {% for cn, color in [(0, "r"), (1, "g"), (2, "b")] %}
  {% for x in c["color_map"][cn] %}
    {{ c.name }}_camera_color_map_{{ color }}[{{ loop.index0 }}] = {{ x }};
  {% endfor %}
 {% endfor %}
{% endfor %}

    vec2 in_coord = vec2(v_texcoord[0] * 1280.0, v_texcoord[1] * 720.0);
    vec2 top_coord = transform_coordinates(in_coord, top_camera);
    vec2 bottom_coord = transform_coordinates(in_coord, bottom_camera);

    mat3 colors_in = mat3(
        vec3(texture2D(tex, vec2(
            top_coord[0] / 1920.0,
            top_coord[1] / 1088.0 / 2.0))),
        vec3(texture2D(tex, vec2(
            bottom_coord[0] / 1920.0,
            bottom_coord[1] / 1088.0 / 2.0 + 0.5))),
        vec3(0., 0., 0.));

    // There's no elementwise abs or clamp for matrices!:
    mat3 weighting = mat3(
        clamp(0.5 - abs(0.5 - colors_in[0]), 0.00001, 1.0),
        clamp(0.5 - abs(0.5 - colors_in[1]), 0.00001, 1.0),
        vec3(0., 0., 0.));
    vec3 weighting_multiplier = 0.5 / (weighting[0] + weighting[1]);
    weighting[0] *= weighting_multiplier;
    weighting[1] *= weighting_multiplier;

    mat3 colors_out = mat3(
        top_camera_color_map_r[int(colors_in[0][0] * 255.)],
        top_camera_color_map_g[int(colors_in[0][1] * 255.)],
        top_camera_color_map_b[int(colors_in[0][2] * 255.)],
        bottom_camera_color_map_r[int(colors_in[1][0] * 255.)],
        bottom_camera_color_map_g[int(colors_in[1][1] * 255.)],
        bottom_camera_color_map_b[int(colors_in[1][2] * 255.)],
        0., 0., 0.);

    gl_FragColor = vec4(
        colors_out[0] * weighting[0] + colors_out[1] * weighting[1], 1.0);
    return;
}

